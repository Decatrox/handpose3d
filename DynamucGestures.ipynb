{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+xIRh+AZplZGLj9GbyzDH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decatrox/handpose3d/blob/AddingRealTime/DynamucGestures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFY77e46PAna"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actions that we try to detect\n",
        "# actions = np.array(['rotateC','rotateAC', 'zoomin', 'zoomout', 'random', 'up2down'])\n",
        "# actions = np.array(['rotateC','rotateAC', 'up2down', 'down2up', 'left2right', 'right2left', 'zoomin', 'zoomout', 'random', 'still'])\n",
        "# actions = np.array(['rotateC','rotateAC', 'up2down', 'down2up', 'left2right', 'right2left', 'zoomin', 'zoomout', 'random'])\n",
        "actions = np.array(['rotateC','rotateAC', 'up2down', 'down2up', 'left2right', 'right2left', 'zoomin', 'zoomout', 'idlec', 'idleac', 'idlefist', 'idlemouse', 'idlezin', 'idlezout'])\n",
        "\n",
        "\n",
        "# actions = np.array(['rotateC','rotateAC', 'zoomin', 'zoomout', 'random', 'still'])\n",
        "\n",
        "# Thirty videos worth of data\n",
        "#no_sequences = 17\n",
        "\n",
        "# Videos are going to be 30 frames in length\n",
        "#sequence_length = 12\n",
        "\n",
        "label_map = {label:num for num, label in enumerate(actions)}"
      ],
      "metadata": {
        "id": "8l-W-4a0Puon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxx = label_map.get('rotateC')\n",
        "idxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyQH-xNxPZSt",
        "outputId": "bb64556e-4653-46de-c3d1-dcdbc3eb50c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map[actions[1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_3c00I0QNFF",
        "outputId": "f16e5c70-1f6f-4dc4-964b-fe6e7f3aa7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmjifbydPxWM",
        "outputId": "69be97d5-de1a-4ebb-c127-90deb24fa42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rotateC': 0,\n",
              " 'rotateAC': 1,\n",
              " 'up2down': 2,\n",
              " 'down2up': 3,\n",
              " 'left2right': 4,\n",
              " 'right2left': 5,\n",
              " 'zoomin': 6,\n",
              " 'zoomout': 7,\n",
              " 'idlec': 8,\n",
              " 'idleac': 9,\n",
              " 'idlefist': 10,\n",
              " 'idlemouse': 11,\n",
              " 'idlezin': 12,\n",
              " 'idlezout': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.loadtxt('Rot/rotClockWiseNew_Omar_2')\n",
        "# a"
      ],
      "metadata": {
        "id": "ppimApKlSW59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "badRot = [138, 107, 34, 139, 128]\n",
        "badRot2 = 52\n",
        "badRotAnti = [49, 57, 81, 91]\n",
        "badZin = [68, 125, 69, 123, 70]\n",
        "badZout = [67, 112]\n",
        "badUp2Down = [10, 11, 25, 42, 44, 60, 77]\n",
        "badRight2Left = [35, 41, 64]\n",
        "badDown2Up = [54, 69, 77, 79, 82, 84, 86]\n",
        "badLeft2Right = [47]"
      ],
      "metadata": {
        "id": "txJONfqGS9Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed length of 12\n",
        "# sequences, labels = [], []\n",
        "# #for action in actions:\n",
        "# for sequence in range(1, 163):\n",
        "#     if not (sequence in badRot):\n",
        "#       window = []\n",
        "#       a = np.loadtxt('data/ClockWiseRotation/testfile'+str(sequence))\n",
        "#       for frame_num in range(12):\n",
        "#           res = a[frame_num]\n",
        "#           window.append(res)\n",
        "#       sequences.append(window)\n",
        "#       labels.append(label_map[actions[0]])\n"
      ],
      "metadata": {
        "id": "7GbDbdLmbZWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences, labels = [], []\n"
      ],
      "metadata": {
        "id": "Ud4YzJlVkJYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences, labels = [], []\n",
        "#ClockWise Rotation\n",
        "#for action in actions:\n",
        "for sequence in range(1, 163):\n",
        "    if not (sequence in badRot):\n",
        "      window = []\n",
        "      a = np.loadtxt('data/ClockWiseRotation/testfile'+str(sequence))\n",
        "      for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "      sequences.append(window)\n",
        "      # labels.append(label_map[actions[0]])\n",
        "      labels.append(label_map.get('rotateC'))"
      ],
      "metadata": {
        "id": "nLj6-PP8V9MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ClockWise Rotation 2\n",
        "#for action in actions:\n",
        "for sequence in range(1, 69):\n",
        "  if not badRot2 == sequence:\n",
        "      window = []\n",
        "      a = np.loadtxt('data/ClockWiseGUC/testfile'+str(sequence))\n",
        "      for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "      sequences.append(window)\n",
        "      # labels.append(label_map[actions[0]])\n",
        "      labels.append(label_map.get('rotateC'))"
      ],
      "metadata": {
        "id": "rlSb_NP0Q42c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Anti-ClockWise Rotation\n",
        "#for action in actions:\n",
        "for sequence in range(1, 110):\n",
        "    if not (sequence in badRotAnti):\n",
        "      window = []\n",
        "      a = np.loadtxt('data/AntiClockWiseRotation/testfile'+str(sequence))\n",
        "      for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "      sequences.append(window)\n",
        "      # labels.append(label_map[actions[1]])\n",
        "      labels.append(label_map.get('rotateAC'))"
      ],
      "metadata": {
        "id": "JUt5uwE3RcyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Zoom In\n",
        "#for action in actions:\n",
        "for sequence in range(1, 156):\n",
        "      if not (sequence in badZin):\n",
        "        window = []\n",
        "        a = np.loadtxt('data/ZoomIn/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[6]])\n",
        "        # labels.append(label_map[actions[2]])\n",
        "        labels.append(label_map.get('zoomin'))"
      ],
      "metadata": {
        "id": "jDPqoLn5jpGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zoom In 2\n",
        "#for action in actions:\n",
        "for sequence in range(1, 35):\n",
        "        window = []\n",
        "        a = np.loadtxt('data/ZoomInGUC/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[6]])\n",
        "        # labels.append(label_map[actions[2]])\n",
        "        labels.append(label_map.get('zoomin'))"
      ],
      "metadata": {
        "id": "HhE62541R_zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zoom Out\n",
        "#for action in actions:\n",
        "for sequence in range(1, 137):\n",
        "      if not (sequence in badZout):\n",
        "        window = []\n",
        "        a = np.loadtxt('data/ZoomOut/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[7]])\n",
        "        # labels.append(label_map[actions[3]])\n",
        "        labels.append(label_map.get('zoomout'))"
      ],
      "metadata": {
        "id": "22bvDm4vj3Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Movements\n",
        "#for action in actions:\n",
        "for sequence in range(1, 94):\n",
        "        window = []\n",
        "        a = np.loadtxt('data/RandomMovements/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[8]])\n",
        "        # labels.append(label_map[actions[4]])\n",
        "        labels.append(label_map.get('random'))"
      ],
      "metadata": {
        "id": "nd9IP082SLUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Up2Down\n",
        "#for action in actions:\n",
        "for sequence in range(1, 122):\n",
        "  if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/Up2Down/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[2]])\n",
        "        labels.append(label_map.get('up2down'))"
      ],
      "metadata": {
        "id": "_mkoEL4QTgHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Down2Up\n",
        "for sequence in range(1, 119):\n",
        "  if not sequence in badDown2Up:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/Down2Up/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[3]])\n",
        "        labels.append(label_map.get('down2up'))"
      ],
      "metadata": {
        "id": "qCoSAbpPVViC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Left2Right\n",
        "for sequence in range(1, 122):\n",
        "  if not sequence in badLeft2Right:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/Left2Right/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[4]])\n",
        "        labels.append(label_map.get('left2right'))"
      ],
      "metadata": {
        "id": "IsulVAQXVX77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Right2Left\n",
        "for sequence in range(1, 100):\n",
        "  if not sequence in badRight2Left:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/Right2Left/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('right2left'))"
      ],
      "metadata": {
        "id": "KtHczsmcVpKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still\n",
        "for sequence in range(1, 88):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/Still/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('random'))"
      ],
      "metadata": {
        "id": "GPSAN95tWlwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still CW\n",
        "for sequence in range(1, 100):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleCW/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idlec'))"
      ],
      "metadata": {
        "id": "ss6AkTM1g8wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still ACW\n",
        "for sequence in range(1, 91):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleACW/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idleac'))"
      ],
      "metadata": {
        "id": "ggJoqyiZhqcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still Mouse\n",
        "for sequence in range(1, 100):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleMouse/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idlemouse'))"
      ],
      "metadata": {
        "id": "h9vIHPU7h4Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still Fist\n",
        "for sequence in range(1, 84):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleFist/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idlefist'))"
      ],
      "metadata": {
        "id": "6WwOFgTgiGgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Still Zoom in\n",
        "for sequence in range(1, 65):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleZin/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idlezin'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMEP7dL2d7h-",
        "outputId": "77d72e32-71a1-4438-9510-1f0834f969a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-899e3af86a90>:5: UserWarning: loadtxt: Empty input file: \"data/IdleZin/testfile1\"\n",
            "  a = np.loadtxt('data/IdleZin/testfile'+str(sequence))\n",
            "<ipython-input-52-899e3af86a90>:5: UserWarning: loadtxt: Empty input file: \"data/IdleZin/testfile14\"\n",
            "  a = np.loadtxt('data/IdleZin/testfile'+str(sequence))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Still Zoom out\n",
        "for sequence in range(1, 75):\n",
        "  # if not sequence in badUp2Down:\n",
        "        window = []\n",
        "        a = np.loadtxt('data/IdleZout/testfile'+str(sequence))\n",
        "        for res in a:\n",
        "          #res = a[frame_num]\n",
        "          window.append(res)\n",
        "        sequences.append(window)\n",
        "        # labels.append(label_map[actions[9]])\n",
        "        # labels.append(label_map[actions[5]])\n",
        "        labels.append(label_map.get('idlezout'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqSSJ7Bpd766",
        "outputId": "86c68a57-fed6-4d74-d8a2-05bb8ddb1e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-b15722e409f3>:5: UserWarning: loadtxt: Empty input file: \"data/IdleZout/testfile15\"\n",
            "  a = np.loadtxt('data/IdleZout/testfile'+str(sequence))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the unchanged one. I will change the above to make sure the data is the same length.\n",
        "# Zoom in is 19. zoomn out and rotate is 20.\n",
        "# #for action in actions:\n",
        "# for sequence in range(1, 20):\n",
        "#     window = []\n",
        "#     a = np.loadtxt('ZOut/ZoomOutNew_Omar_'+str(sequence))\n",
        "#     for frame_num in range(len(a)):\n",
        "#         res = a[frame_num]\n",
        "#         window.append(res)\n",
        "#     sequences.append(window)\n",
        "#     labels.append(label_map[actions[2]])"
      ],
      "metadata": {
        "id": "kiYHTlLxoW79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.array(sequences, dtype=object)"
      ],
      "metadata": {
        "id": "doCwpVOolBxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#sequences = pad_sequences(sequences, maxlen=20, padding='post', value=0)\n",
        "# sequences = pad_sequences(sequences, maxlen=20, padding='post', value=-1)\n",
        "sequences = pad_sequences(sequences, maxlen=15, padding='post', value=-1)"
      ],
      "metadata": {
        "id": "MSxsdtgmYg92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(sequences)"
      ],
      "metadata": {
        "id": "TxSGcFWIXhB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(labels).astype(int)"
      ],
      "metadata": {
        "id": "Zcm-EeP0je01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "tHOTNkWyjgCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfdb60b-f920-4fd5-a3ba-52bdfc078718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "metadata": {
        "id": "WjytCY0jk4Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If using new model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split the data into a training set and a temporary set using an 80:20 ratio\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "# Then split the temporary set into validation and test sets using a 50:50 ratio\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50)\n"
      ],
      "metadata": {
        "id": "jQauFIxHdS81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpDFXCi0lHw0",
        "outputId": "0717dded-ce5f-47df-99e4-054e041c72cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJZqqQQk0k6A",
        "outputId": "7cfff581-189b-4857-8c11-43aab8874c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1437, 15, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WWJnq660sMw",
        "outputId": "a61e7ab6-d54b-4396-e013-6bd7f4906e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1437, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6KCwjjQTZN5",
        "outputId": "0ea60c61-d32d-458e-eccc-a9dc24619d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1597, 15, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x and y are not the same shape\n",
        "y_train = y_train.reshape((678, 5))"
      ],
      "metadata": {
        "id": "dx6IL0Z8Uu7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train[:X.shape[0], :]\n"
      ],
      "metadata": {
        "id": "ZcQpEToJaYXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**\n"
      ],
      "metadata": {
        "id": "2qEPBZYflKX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Masking\n",
        "import tensorflow.keras.layers"
      ],
      "metadata": {
        "id": "Yh1fbZAclTBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow.keras.layers.Reshape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "mfBL1jaNVgh2",
        "outputId": "9e3aedfe-314b-4d8e-912b-e67a971836df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-9734d7dd49b4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Reshape.__init__() missing 1 required positional argument: 'target_shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "log_dir = os.path.join('Logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "QCi6BAs0lXwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layers\n",
        "model = Sequential()\n",
        "# model.add(Masking(mask_value=-1, input_shape=(20, 63)))\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(20, 63)))\n",
        "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#if no certain shape\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(None, 63)))\n",
        "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(actions.shape[0], activation='softmax'))"
      ],
      "metadata": {
        "id": "iv9mlTpXmoEh",
        "outputId": "2b885ffc-1d2a-4bf8-fd9c-03abe7e6f3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3ef5d2f6fb92>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.add(Masking(mask_value=-1, input_shape=(20, 63)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])\n"
      ],
      "metadata": {
        "id": "5F_WNw1ocEpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 0 81%\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "_UOy2SLsfsbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 4x\n",
        "# Test 0 81%\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(256))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "0Tesfcr0vLni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 1 -> 60%\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "tbEupdyeaBMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 2 -> %\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(LSTM(128))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.02)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.02)))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),  #0.001\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "YGPbR6s6aRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr72ptrfgWPp",
        "outputId": "4804b094-6e4d-4ca6-8d66-d3a89532b8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 15, 63)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 15, 128)           98304     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 128)           0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 15, 256)           394240    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 15, 256)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 700,330\n",
            "Trainable params: 700,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 3 -> 51%\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "# Use GRU instead of LSTM\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(64))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.02)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.02)))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "yrYuxy4Xah_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 4 -> 61%\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "#Test 3\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "# Use 1D Convolutional layer\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(15, 63)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# LSTM layers with dropout for regularization\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "\n",
        "# Dense layers with dropout for regularization\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "l6JETQmfa8mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False, activation='relu')))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "C0QoRUrMkmc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test conv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout, Conv3D, MaxPooling3D, BatchNormalization, TimeDistributed, Lambda\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=-1, input_shape=(15, 63)))\n",
        "\n",
        "\n",
        "model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), strides=(1, 2, 2), padding='valid', data_format='channels_last'))\n",
        "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
        "model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), padding='valid'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
        "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='valid'))\n",
        "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='valid'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
        "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='valid'))\n",
        "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='valid'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Th2w21Ja1wu4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7cb9e29c-056b-4fd6-b455-3a3eda7bc870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-8e5381d7cc10>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv3d_28\" is incompatible with the layer: expected min_ndim=5, found ndim=3. Full shape received: (None, 15, 63)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['categorical_accuracy'])\n"
      ],
      "metadata": {
        "id": "j8DTJXXQvTXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=400,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=16)] #patience=10\n",
        "    # callbacks=[EarlyStopping(monitor='categorical_accuracy', patience=16)] #patience=10\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "KH_9BvCYcyH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No validation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=600,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[EarlyStopping(monitor='loss', patience=60)] #patience=10\n",
        "    # callbacks=[EarlyStopping(monitor='categorical_accuracy', patience=16)] #patience=10\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "AgesjhegSXYq",
        "outputId": "15db9c8d-a419-458c-fb7f-1ae697c42b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-28e50b823b6f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_16' (type Sequential).\n    \n    Input 0 of layer \"conv3d_21\" is incompatible with the layer: expected min_ndim=5, found ndim=3. Full shape received: (None, 15, 63)\n    \n    Call arguments received by layer 'sequential_16' (type Sequential):\n       inputs=tf.Tensor(shape=(None, 15, 63), dtype=int32)\n       training=True\n       mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# maxlen = 20\n",
        "# X = [pad_sequences(seq, maxlen=maxlen) for seq in sequences]\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Masking(mask_value=-1, input_shape=(maxlen, 63)))\n",
        "# model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
        "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(actions.shape[0], activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HZSF4ugoRW1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=600, callbacks=[tb_callback])"
      ],
      "metadata": {
        "id": "ORDIfVc8SBPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = [.7, 0.2, 0.1]"
      ],
      "metadata": {
        "id": "SjGX9KdnmyV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions[np.argmax(res)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "456MONvfmzo1",
        "outputId": "2bc6724f-1f76-4177-a8cc-8308b8903e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rotateC'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "jGQLwkC4m3nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=400, callbacks=[tb_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAxgRRy4n2r7",
        "outputId": "193e821c-5283-4f3d-9457-c3de8dae634f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "22/22 [==============================] - 9s 64ms/step - loss: 7.5309 - categorical_accuracy: 0.2197\n",
            "Epoch 2/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 3.6841 - categorical_accuracy: 0.2454\n",
            "Epoch 3/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 1.6388 - categorical_accuracy: 0.3466\n",
            "Epoch 4/400\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 1.5791 - categorical_accuracy: 0.4137\n",
            "Epoch 5/400\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 1.5453 - categorical_accuracy: 0.3381\n",
            "Epoch 6/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.3481 - categorical_accuracy: 0.4465\n",
            "Epoch 7/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 1.2779 - categorical_accuracy: 0.4636\n",
            "Epoch 8/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.1947 - categorical_accuracy: 0.4679\n",
            "Epoch 9/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.1040 - categorical_accuracy: 0.5164\n",
            "Epoch 10/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 1.1271 - categorical_accuracy: 0.5178\n",
            "Epoch 11/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 1.1771 - categorical_accuracy: 0.4650\n",
            "Epoch 12/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.0564 - categorical_accuracy: 0.5235\n",
            "Epoch 13/400\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 0.9317 - categorical_accuracy: 0.6334\n",
            "Epoch 14/400\n",
            "22/22 [==============================] - 3s 128ms/step - loss: 0.9116 - categorical_accuracy: 0.6448\n",
            "Epoch 15/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 5.2352 - categorical_accuracy: 0.3252\n",
            "Epoch 16/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 2.3070 - categorical_accuracy: 0.2668\n",
            "Epoch 17/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.6402 - categorical_accuracy: 0.3738\n",
            "Epoch 18/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.5468 - categorical_accuracy: 0.3752\n",
            "Epoch 19/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.4591 - categorical_accuracy: 0.4208\n",
            "Epoch 20/400\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 1.3934 - categorical_accuracy: 0.4565\n",
            "Epoch 21/400\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 2.9061 - categorical_accuracy: 0.4736\n",
            "Epoch 22/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 4.5063 - categorical_accuracy: 0.5036\n",
            "Epoch 23/400\n",
            "22/22 [==============================] - 2s 104ms/step - loss: 5.4219 - categorical_accuracy: 0.4650\n",
            "Epoch 24/400\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 1.3885 - categorical_accuracy: 0.4822\n",
            "Epoch 25/400\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 1.4457 - categorical_accuracy: 0.5050\n",
            "Epoch 26/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.3150 - categorical_accuracy: 0.4922\n",
            "Epoch 27/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.1302 - categorical_accuracy: 0.5407\n",
            "Epoch 28/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.1381 - categorical_accuracy: 0.5207\n",
            "Epoch 29/400\n",
            "22/22 [==============================] - 2s 96ms/step - loss: 1.6351 - categorical_accuracy: 0.5093\n",
            "Epoch 30/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 1.4417 - categorical_accuracy: 0.5278\n",
            "Epoch 31/400\n",
            "22/22 [==============================] - 2s 78ms/step - loss: 1.2827 - categorical_accuracy: 0.4979\n",
            "Epoch 32/400\n",
            "22/22 [==============================] - 3s 114ms/step - loss: 1.0714 - categorical_accuracy: 0.5492\n",
            "Epoch 33/400\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 1.0734 - categorical_accuracy: 0.5749\n",
            "Epoch 34/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.1130 - categorical_accuracy: 0.5863\n",
            "Epoch 35/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.8963 - categorical_accuracy: 0.6148\n",
            "Epoch 36/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.8303 - categorical_accuracy: 0.6434\n",
            "Epoch 37/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.8287 - categorical_accuracy: 0.6591\n",
            "Epoch 38/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.8156 - categorical_accuracy: 0.6491\n",
            "Epoch 39/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.8584 - categorical_accuracy: 0.6148\n",
            "Epoch 40/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.7661 - categorical_accuracy: 0.6748\n",
            "Epoch 41/400\n",
            "22/22 [==============================] - 3s 122ms/step - loss: 0.7210 - categorical_accuracy: 0.6847\n",
            "Epoch 42/400\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.6506 - categorical_accuracy: 0.7147\n",
            "Epoch 43/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.6597 - categorical_accuracy: 0.7332\n",
            "Epoch 44/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.6904 - categorical_accuracy: 0.7261\n",
            "Epoch 45/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.6518 - categorical_accuracy: 0.7332\n",
            "Epoch 46/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.6283 - categorical_accuracy: 0.7261\n",
            "Epoch 47/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.5990 - categorical_accuracy: 0.7646\n",
            "Epoch 48/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.5564 - categorical_accuracy: 0.7660\n",
            "Epoch 49/400\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.5355 - categorical_accuracy: 0.8003\n",
            "Epoch 50/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.5059 - categorical_accuracy: 0.7989\n",
            "Epoch 51/400\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5611 - categorical_accuracy: 0.7860\n",
            "Epoch 52/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.5318 - categorical_accuracy: 0.7817\n",
            "Epoch 53/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.5642 - categorical_accuracy: 0.7603\n",
            "Epoch 54/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.6057 - categorical_accuracy: 0.7817\n",
            "Epoch 55/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 6.2898 - categorical_accuracy: 0.4237\n",
            "Epoch 56/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.8678 - categorical_accuracy: 0.2639\n",
            "Epoch 57/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.6851 - categorical_accuracy: 0.3195\n",
            "Epoch 58/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.5281 - categorical_accuracy: 0.3752\n",
            "Epoch 59/400\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 1.4015 - categorical_accuracy: 0.4194\n",
            "Epoch 60/400\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 1.3749 - categorical_accuracy: 0.4023\n",
            "Epoch 61/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.3683 - categorical_accuracy: 0.4308\n",
            "Epoch 62/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 1.2686 - categorical_accuracy: 0.4151\n",
            "Epoch 63/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 1.2170 - categorical_accuracy: 0.4693\n",
            "Epoch 64/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.1677 - categorical_accuracy: 0.4565\n",
            "Epoch 65/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.1562 - categorical_accuracy: 0.4579\n",
            "Epoch 66/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.1786 - categorical_accuracy: 0.4522\n",
            "Epoch 67/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.1017 - categorical_accuracy: 0.5021\n",
            "Epoch 68/400\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 1.1473 - categorical_accuracy: 0.4536\n",
            "Epoch 69/400\n",
            "22/22 [==============================] - 3s 118ms/step - loss: 1.1042 - categorical_accuracy: 0.4693\n",
            "Epoch 70/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.0369 - categorical_accuracy: 0.5235\n",
            "Epoch 71/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.0519 - categorical_accuracy: 0.5178\n",
            "Epoch 72/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.1203 - categorical_accuracy: 0.4964\n",
            "Epoch 73/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.1475 - categorical_accuracy: 0.4579\n",
            "Epoch 74/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.0322 - categorical_accuracy: 0.5050\n",
            "Epoch 75/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.9142 - categorical_accuracy: 0.5949\n",
            "Epoch 76/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.9226 - categorical_accuracy: 0.5877\n",
            "Epoch 77/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.9603 - categorical_accuracy: 0.5720\n",
            "Epoch 78/400\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.9718 - categorical_accuracy: 0.5592\n",
            "Epoch 79/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.8867 - categorical_accuracy: 0.6049\n",
            "Epoch 80/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.9540 - categorical_accuracy: 0.5706\n",
            "Epoch 81/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.8327 - categorical_accuracy: 0.6305\n",
            "Epoch 82/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.8008 - categorical_accuracy: 0.6491\n",
            "Epoch 83/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.7613 - categorical_accuracy: 0.6619\n",
            "Epoch 84/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.7232 - categorical_accuracy: 0.6904\n",
            "Epoch 85/400\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 0.7226 - categorical_accuracy: 0.6805\n",
            "Epoch 86/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.6906 - categorical_accuracy: 0.7004\n",
            "Epoch 87/400\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.7198 - categorical_accuracy: 0.6805\n",
            "Epoch 88/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.7272 - categorical_accuracy: 0.6762\n",
            "Epoch 89/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.7199 - categorical_accuracy: 0.7076\n",
            "Epoch 90/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.6455 - categorical_accuracy: 0.7318\n",
            "Epoch 91/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.6099 - categorical_accuracy: 0.7347\n",
            "Epoch 92/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.6366 - categorical_accuracy: 0.7304\n",
            "Epoch 93/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.6818 - categorical_accuracy: 0.6876\n",
            "Epoch 94/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.6464 - categorical_accuracy: 0.7147\n",
            "Epoch 95/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.6321 - categorical_accuracy: 0.7404\n",
            "Epoch 96/400\n",
            "22/22 [==============================] - 3s 114ms/step - loss: 0.6758 - categorical_accuracy: 0.7104\n",
            "Epoch 97/400\n",
            "22/22 [==============================] - 2s 67ms/step - loss: 0.6489 - categorical_accuracy: 0.7218\n",
            "Epoch 98/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.6110 - categorical_accuracy: 0.7361\n",
            "Epoch 99/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.5661 - categorical_accuracy: 0.7575\n",
            "Epoch 100/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.5364 - categorical_accuracy: 0.7689\n",
            "Epoch 101/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.5498 - categorical_accuracy: 0.7703\n",
            "Epoch 102/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.6285 - categorical_accuracy: 0.7161\n",
            "Epoch 103/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.6190 - categorical_accuracy: 0.7475\n",
            "Epoch 104/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.5606 - categorical_accuracy: 0.7689\n",
            "Epoch 105/400\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.5181 - categorical_accuracy: 0.7760\n",
            "Epoch 106/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.5372 - categorical_accuracy: 0.7846\n",
            "Epoch 107/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.5379 - categorical_accuracy: 0.7660\n",
            "Epoch 108/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.5659 - categorical_accuracy: 0.7646\n",
            "Epoch 109/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.5559 - categorical_accuracy: 0.7889\n",
            "Epoch 110/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.4867 - categorical_accuracy: 0.8046\n",
            "Epoch 111/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.5001 - categorical_accuracy: 0.8046\n",
            "Epoch 112/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.6352 - categorical_accuracy: 0.7475\n",
            "Epoch 113/400\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.6926 - categorical_accuracy: 0.7175\n",
            "Epoch 114/400\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.5123 - categorical_accuracy: 0.8103\n",
            "Epoch 115/400\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.4821 - categorical_accuracy: 0.7917\n",
            "Epoch 116/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.4847 - categorical_accuracy: 0.8103\n",
            "Epoch 117/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.4608 - categorical_accuracy: 0.8160\n",
            "Epoch 118/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.4686 - categorical_accuracy: 0.8088\n",
            "Epoch 119/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.4702 - categorical_accuracy: 0.8117\n",
            "Epoch 120/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.5261 - categorical_accuracy: 0.7789\n",
            "Epoch 121/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.4843 - categorical_accuracy: 0.7903\n",
            "Epoch 122/400\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.4583 - categorical_accuracy: 0.8131\n",
            "Epoch 123/400\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.4329 - categorical_accuracy: 0.8245\n",
            "Epoch 124/400\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 0.4209 - categorical_accuracy: 0.8274\n",
            "Epoch 125/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.4442 - categorical_accuracy: 0.8331\n",
            "Epoch 126/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.4536 - categorical_accuracy: 0.8103\n",
            "Epoch 127/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.3921 - categorical_accuracy: 0.8445\n",
            "Epoch 128/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.3632 - categorical_accuracy: 0.8659\n",
            "Epoch 129/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3737 - categorical_accuracy: 0.8602\n",
            "Epoch 130/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4176 - categorical_accuracy: 0.8402\n",
            "Epoch 131/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.4242 - categorical_accuracy: 0.8302\n",
            "Epoch 132/400\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.4677 - categorical_accuracy: 0.8074\n",
            "Epoch 133/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.3934 - categorical_accuracy: 0.8374\n",
            "Epoch 134/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.3506 - categorical_accuracy: 0.8645\n",
            "Epoch 135/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.4253 - categorical_accuracy: 0.8317\n",
            "Epoch 136/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.4110 - categorical_accuracy: 0.8217\n",
            "Epoch 137/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.4195 - categorical_accuracy: 0.8217\n",
            "Epoch 138/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.3865 - categorical_accuracy: 0.8459\n",
            "Epoch 139/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.3700 - categorical_accuracy: 0.8502\n",
            "Epoch 140/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.4412 - categorical_accuracy: 0.8131\n",
            "Epoch 141/400\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.4227 - categorical_accuracy: 0.8374\n",
            "Epoch 142/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.3590 - categorical_accuracy: 0.8516\n",
            "Epoch 143/400\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.3388 - categorical_accuracy: 0.8588\n",
            "Epoch 144/400\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.3460 - categorical_accuracy: 0.8588\n",
            "Epoch 145/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.3618 - categorical_accuracy: 0.8545\n",
            "Epoch 146/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.3276 - categorical_accuracy: 0.8787\n",
            "Epoch 147/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3377 - categorical_accuracy: 0.8673\n",
            "Epoch 148/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.4904 - categorical_accuracy: 0.8046\n",
            "Epoch 149/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4458 - categorical_accuracy: 0.8046\n",
            "Epoch 150/400\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.4285 - categorical_accuracy: 0.8374\n",
            "Epoch 151/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.3696 - categorical_accuracy: 0.8745\n",
            "Epoch 152/400\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 0.3012 - categorical_accuracy: 0.8773\n",
            "Epoch 153/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.2984 - categorical_accuracy: 0.8959\n",
            "Epoch 154/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.3070 - categorical_accuracy: 0.8845\n",
            "Epoch 155/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.3363 - categorical_accuracy: 0.8745\n",
            "Epoch 156/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.5139 - categorical_accuracy: 0.8188\n",
            "Epoch 157/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3935 - categorical_accuracy: 0.8488\n",
            "Epoch 158/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.5791 - categorical_accuracy: 0.7917\n",
            "Epoch 159/400\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.5458 - categorical_accuracy: 0.7404\n",
            "Epoch 160/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.4132 - categorical_accuracy: 0.8573\n",
            "Epoch 161/400\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.3405 - categorical_accuracy: 0.8730\n",
            "Epoch 162/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3361 - categorical_accuracy: 0.8631\n",
            "Epoch 163/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.3065 - categorical_accuracy: 0.8816\n",
            "Epoch 164/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.3616 - categorical_accuracy: 0.8616\n",
            "Epoch 165/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.9126 - categorical_accuracy: 0.7332\n",
            "Epoch 166/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.0046 - categorical_accuracy: 0.6320\n",
            "Epoch 167/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.6306 - categorical_accuracy: 0.7603\n",
            "Epoch 168/400\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 0.5245 - categorical_accuracy: 0.7960\n",
            "Epoch 169/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.4555 - categorical_accuracy: 0.8131\n",
            "Epoch 170/400\n",
            "22/22 [==============================] - 2s 85ms/step - loss: 0.5880 - categorical_accuracy: 0.8088\n",
            "Epoch 171/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4885 - categorical_accuracy: 0.8260\n",
            "Epoch 172/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.3806 - categorical_accuracy: 0.8673\n",
            "Epoch 173/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.3259 - categorical_accuracy: 0.8730\n",
            "Epoch 174/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.3051 - categorical_accuracy: 0.8787\n",
            "Epoch 175/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2659 - categorical_accuracy: 0.9001\n",
            "Epoch 176/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.3207 - categorical_accuracy: 0.8688\n",
            "Epoch 177/400\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.3819 - categorical_accuracy: 0.8502\n",
            "Epoch 178/400\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.3548 - categorical_accuracy: 0.8645\n",
            "Epoch 179/400\n",
            "22/22 [==============================] - 2s 76ms/step - loss: 0.2751 - categorical_accuracy: 0.8887\n",
            "Epoch 180/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.2931 - categorical_accuracy: 0.8930\n",
            "Epoch 181/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.3549 - categorical_accuracy: 0.8559\n",
            "Epoch 182/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2822 - categorical_accuracy: 0.8944\n",
            "Epoch 183/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.2720 - categorical_accuracy: 0.9001\n",
            "Epoch 184/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.6069 - categorical_accuracy: 0.8260\n",
            "Epoch 185/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.5851 - categorical_accuracy: 0.7803\n",
            "Epoch 186/400\n",
            "22/22 [==============================] - 2s 98ms/step - loss: 0.3234 - categorical_accuracy: 0.8802\n",
            "Epoch 187/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.2654 - categorical_accuracy: 0.9058\n",
            "Epoch 188/400\n",
            "22/22 [==============================] - 2s 83ms/step - loss: 0.2240 - categorical_accuracy: 0.9230\n",
            "Epoch 189/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2913 - categorical_accuracy: 0.8930\n",
            "Epoch 190/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.4880 - categorical_accuracy: 0.8245\n",
            "Epoch 191/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2766 - categorical_accuracy: 0.9173\n",
            "Epoch 192/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2079 - categorical_accuracy: 0.9287\n",
            "Epoch 193/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.1854 - categorical_accuracy: 0.9287\n",
            "Epoch 194/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1806 - categorical_accuracy: 0.9387\n",
            "Epoch 195/400\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.1862 - categorical_accuracy: 0.9258\n",
            "Epoch 196/400\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.4365 - categorical_accuracy: 0.8502\n",
            "Epoch 197/400\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.4975 - categorical_accuracy: 0.8359\n",
            "Epoch 198/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.2808 - categorical_accuracy: 0.9087\n",
            "Epoch 199/400\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.1947 - categorical_accuracy: 0.9372\n",
            "Epoch 200/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2181 - categorical_accuracy: 0.9330\n",
            "Epoch 201/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2149 - categorical_accuracy: 0.9230\n",
            "Epoch 202/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2063 - categorical_accuracy: 0.9187\n",
            "Epoch 203/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4408 - categorical_accuracy: 0.8516\n",
            "Epoch 204/400\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.3530 - categorical_accuracy: 0.8573\n",
            "Epoch 205/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.2520 - categorical_accuracy: 0.9101\n",
            "Epoch 206/400\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 0.2058 - categorical_accuracy: 0.9330\n",
            "Epoch 207/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.1728 - categorical_accuracy: 0.9444\n",
            "Epoch 208/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2230 - categorical_accuracy: 0.9215\n",
            "Epoch 209/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2870 - categorical_accuracy: 0.8873\n",
            "Epoch 210/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.6104 - categorical_accuracy: 0.7903\n",
            "Epoch 211/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.4614 - categorical_accuracy: 0.8131\n",
            "Epoch 212/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.3300 - categorical_accuracy: 0.8673\n",
            "Epoch 213/400\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.4161 - categorical_accuracy: 0.9101\n",
            "Epoch 214/400\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 0.2254 - categorical_accuracy: 0.9244\n",
            "Epoch 215/400\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 0.3062 - categorical_accuracy: 0.8887\n",
            "Epoch 216/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2311 - categorical_accuracy: 0.9230\n",
            "Epoch 217/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.1816 - categorical_accuracy: 0.9387\n",
            "Epoch 218/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2008 - categorical_accuracy: 0.9387\n",
            "Epoch 219/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.2890 - categorical_accuracy: 0.8959\n",
            "Epoch 220/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.2017 - categorical_accuracy: 0.9358\n",
            "Epoch 221/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2030 - categorical_accuracy: 0.9415\n",
            "Epoch 222/400\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 0.2523 - categorical_accuracy: 0.9044\n",
            "Epoch 223/400\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 0.2958 - categorical_accuracy: 0.9001\n",
            "Epoch 224/400\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 0.3304 - categorical_accuracy: 0.8773\n",
            "Epoch 225/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1906 - categorical_accuracy: 0.9344\n",
            "Epoch 226/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1647 - categorical_accuracy: 0.9415\n",
            "Epoch 227/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1436 - categorical_accuracy: 0.9529\n",
            "Epoch 228/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1358 - categorical_accuracy: 0.9529\n",
            "Epoch 229/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.6450 - categorical_accuracy: 0.7832\n",
            "Epoch 230/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.5361 - categorical_accuracy: 0.8060\n",
            "Epoch 231/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.3663 - categorical_accuracy: 0.8730\n",
            "Epoch 232/400\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 0.3426 - categorical_accuracy: 0.8859\n",
            "Epoch 233/400\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.2558 - categorical_accuracy: 0.9173\n",
            "Epoch 234/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.2439 - categorical_accuracy: 0.9144\n",
            "Epoch 235/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.2403 - categorical_accuracy: 0.9087\n",
            "Epoch 236/400\n",
            "22/22 [==============================] - 1s 63ms/step - loss: 0.2769 - categorical_accuracy: 0.8973\n",
            "Epoch 237/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.3031 - categorical_accuracy: 0.8816\n",
            "Epoch 238/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.2120 - categorical_accuracy: 0.9244\n",
            "Epoch 239/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.3172 - categorical_accuracy: 0.8859\n",
            "Epoch 240/400\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.2312 - categorical_accuracy: 0.9158\n",
            "Epoch 241/400\n",
            "22/22 [==============================] - 3s 114ms/step - loss: 0.2368 - categorical_accuracy: 0.9272\n",
            "Epoch 242/400\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.2655 - categorical_accuracy: 0.9044\n",
            "Epoch 243/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2639 - categorical_accuracy: 0.9201\n",
            "Epoch 244/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2819 - categorical_accuracy: 0.8987\n",
            "Epoch 245/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.2016 - categorical_accuracy: 0.9358\n",
            "Epoch 246/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1509 - categorical_accuracy: 0.9501\n",
            "Epoch 247/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1732 - categorical_accuracy: 0.9444\n",
            "Epoch 248/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.2467 - categorical_accuracy: 0.9215\n",
            "Epoch 249/400\n",
            "22/22 [==============================] - 3s 116ms/step - loss: 0.2507 - categorical_accuracy: 0.8987\n",
            "Epoch 250/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.1513 - categorical_accuracy: 0.9472\n",
            "Epoch 251/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.1612 - categorical_accuracy: 0.9415\n",
            "Epoch 252/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.1451 - categorical_accuracy: 0.9429\n",
            "Epoch 253/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.1600 - categorical_accuracy: 0.9387\n",
            "Epoch 254/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 0.8471 - categorical_accuracy: 0.8388\n",
            "Epoch 255/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.5202 - categorical_accuracy: 0.7646\n",
            "Epoch 256/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.3304 - categorical_accuracy: 0.8944\n",
            "Epoch 257/400\n",
            "22/22 [==============================] - 2s 73ms/step - loss: 0.3495 - categorical_accuracy: 0.8873\n",
            "Epoch 258/400\n",
            "22/22 [==============================] - 3s 116ms/step - loss: 0.2171 - categorical_accuracy: 0.9315\n",
            "Epoch 259/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.1513 - categorical_accuracy: 0.9515\n",
            "Epoch 260/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.1488 - categorical_accuracy: 0.9529\n",
            "Epoch 261/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2179 - categorical_accuracy: 0.9472\n",
            "Epoch 262/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.2243 - categorical_accuracy: 0.9572\n",
            "Epoch 263/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.1492 - categorical_accuracy: 0.9472\n",
            "Epoch 264/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.2317 - categorical_accuracy: 0.9244\n",
            "Epoch 265/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.2546 - categorical_accuracy: 0.9244\n",
            "Epoch 266/400\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 0.2669 - categorical_accuracy: 0.9315\n",
            "Epoch 267/400\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.1387 - categorical_accuracy: 0.9529\n",
            "Epoch 268/400\n",
            "22/22 [==============================] - 2s 103ms/step - loss: 0.1076 - categorical_accuracy: 0.9700\n",
            "Epoch 269/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 0.0982 - categorical_accuracy: 0.9643\n",
            "Epoch 270/400\n",
            "22/22 [==============================] - 1s 62ms/step - loss: 0.0617 - categorical_accuracy: 0.9815\n",
            "Epoch 271/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 0.0820 - categorical_accuracy: 0.9757\n",
            "Epoch 272/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.1351 - categorical_accuracy: 0.9572\n",
            "Epoch 273/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 0.1919 - categorical_accuracy: 0.9287\n",
            "Epoch 274/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 0.1368 - categorical_accuracy: 0.9472\n",
            "Epoch 275/400\n",
            "22/22 [==============================] - 2s 77ms/step - loss: 1.1656 - categorical_accuracy: 0.7889\n",
            "Epoch 276/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 14.2031 - categorical_accuracy: 0.2168\n",
            "Epoch 277/400\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 3.7042 - categorical_accuracy: 0.2825\n",
            "Epoch 278/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.4682 - categorical_accuracy: 0.3566\n",
            "Epoch 279/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.4168 - categorical_accuracy: 0.3709\n",
            "Epoch 280/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 2.0433 - categorical_accuracy: 0.3581\n",
            "Epoch 281/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6020 - categorical_accuracy: 0.3395\n",
            "Epoch 282/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.3795 - categorical_accuracy: 0.3609\n",
            "Epoch 283/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.4902 - categorical_accuracy: 0.3181\n",
            "Epoch 284/400\n",
            "22/22 [==============================] - 2s 91ms/step - loss: 1.4333 - categorical_accuracy: 0.3909\n",
            "Epoch 285/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 1.4529 - categorical_accuracy: 0.3752\n",
            "Epoch 286/400\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 1.3644 - categorical_accuracy: 0.4180\n",
            "Epoch 287/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.2976 - categorical_accuracy: 0.4337\n",
            "Epoch 288/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.2557 - categorical_accuracy: 0.4722\n",
            "Epoch 289/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.2493 - categorical_accuracy: 0.4394\n",
            "Epoch 290/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.1976 - categorical_accuracy: 0.4650\n",
            "Epoch 291/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.1573 - categorical_accuracy: 0.4836\n",
            "Epoch 292/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 1.2376 - categorical_accuracy: 0.4650\n",
            "Epoch 293/400\n",
            "22/22 [==============================] - 2s 97ms/step - loss: 2.8321 - categorical_accuracy: 0.4365\n",
            "Epoch 294/400\n",
            "22/22 [==============================] - 2s 114ms/step - loss: 2.9516 - categorical_accuracy: 0.1270\n",
            "Epoch 295/400\n",
            "22/22 [==============================] - 2s 84ms/step - loss: 1.7986 - categorical_accuracy: 0.2839\n",
            "Epoch 296/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 5.6258 - categorical_accuracy: 0.2710\n",
            "Epoch 297/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 3.2504 - categorical_accuracy: 0.1469\n",
            "Epoch 298/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 4.9663 - categorical_accuracy: 0.1883\n",
            "Epoch 299/400\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 1.8652 - categorical_accuracy: 0.1270\n",
            "Epoch 300/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.7871 - categorical_accuracy: 0.1155\n",
            "Epoch 301/400\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 1.7599 - categorical_accuracy: 0.1184\n",
            "Epoch 302/400\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 1.7504 - categorical_accuracy: 0.1184\n",
            "Epoch 303/400\n",
            "22/22 [==============================] - 3s 116ms/step - loss: 1.7420 - categorical_accuracy: 0.1184\n",
            "Epoch 304/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.7347 - categorical_accuracy: 0.1198\n",
            "Epoch 305/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.7583 - categorical_accuracy: 0.1270\n",
            "Epoch 306/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.7231 - categorical_accuracy: 0.1184\n",
            "Epoch 307/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.7180 - categorical_accuracy: 0.2739\n",
            "Epoch 308/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.7133 - categorical_accuracy: 0.2910\n",
            "Epoch 309/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.7089 - categorical_accuracy: 0.2910\n",
            "Epoch 310/400\n",
            "22/22 [==============================] - 2s 79ms/step - loss: 1.7052 - categorical_accuracy: 0.2910\n",
            "Epoch 311/400\n",
            "22/22 [==============================] - 3s 113ms/step - loss: 1.7017 - categorical_accuracy: 0.2910\n",
            "Epoch 312/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 1.6987 - categorical_accuracy: 0.2910\n",
            "Epoch 313/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.6956 - categorical_accuracy: 0.2910\n",
            "Epoch 314/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6930 - categorical_accuracy: 0.2910\n",
            "Epoch 315/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6905 - categorical_accuracy: 0.2910\n",
            "Epoch 316/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.6883 - categorical_accuracy: 0.2896\n",
            "Epoch 317/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6862 - categorical_accuracy: 0.2896\n",
            "Epoch 318/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.6843 - categorical_accuracy: 0.2896\n",
            "Epoch 319/400\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 1.6826 - categorical_accuracy: 0.2896\n",
            "Epoch 320/400\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 1.6810 - categorical_accuracy: 0.2896\n",
            "Epoch 321/400\n",
            "22/22 [==============================] - 2s 100ms/step - loss: 1.6794 - categorical_accuracy: 0.2910\n",
            "Epoch 322/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6781 - categorical_accuracy: 0.2910\n",
            "Epoch 323/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.6767 - categorical_accuracy: 0.2910\n",
            "Epoch 324/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6756 - categorical_accuracy: 0.2910\n",
            "Epoch 325/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6745 - categorical_accuracy: 0.2910\n",
            "Epoch 326/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6733 - categorical_accuracy: 0.2910\n",
            "Epoch 327/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.6723 - categorical_accuracy: 0.2882\n",
            "Epoch 328/400\n",
            "22/22 [==============================] - 2s 88ms/step - loss: 1.6713 - categorical_accuracy: 0.2910\n",
            "Epoch 329/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 1.6704 - categorical_accuracy: 0.2910\n",
            "Epoch 330/400\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 1.6695 - categorical_accuracy: 0.2910\n",
            "Epoch 331/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6689 - categorical_accuracy: 0.2910\n",
            "Epoch 332/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6682 - categorical_accuracy: 0.2910\n",
            "Epoch 333/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 1.6673 - categorical_accuracy: 0.2910\n",
            "Epoch 334/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.6668 - categorical_accuracy: 0.2910\n",
            "Epoch 335/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6662 - categorical_accuracy: 0.2910\n",
            "Epoch 336/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.6657 - categorical_accuracy: 0.2910\n",
            "Epoch 337/400\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 1.6651 - categorical_accuracy: 0.2910\n",
            "Epoch 338/400\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 1.6647 - categorical_accuracy: 0.2910\n",
            "Epoch 339/400\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 1.6642 - categorical_accuracy: 0.2910\n",
            "Epoch 340/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.6637 - categorical_accuracy: 0.2910\n",
            "Epoch 341/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6633 - categorical_accuracy: 0.2910\n",
            "Epoch 342/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6629 - categorical_accuracy: 0.2910\n",
            "Epoch 343/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6625 - categorical_accuracy: 0.2910\n",
            "Epoch 344/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6623 - categorical_accuracy: 0.2910\n",
            "Epoch 345/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6621 - categorical_accuracy: 0.2910\n",
            "Epoch 346/400\n",
            "22/22 [==============================] - 3s 116ms/step - loss: 1.6618 - categorical_accuracy: 0.2910\n",
            "Epoch 347/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 1.6614 - categorical_accuracy: 0.2910\n",
            "Epoch 348/400\n",
            "22/22 [==============================] - 2s 76ms/step - loss: 1.6610 - categorical_accuracy: 0.2910\n",
            "Epoch 349/400\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 1.6606 - categorical_accuracy: 0.2910\n",
            "Epoch 350/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6603 - categorical_accuracy: 0.2910\n",
            "Epoch 351/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.6599 - categorical_accuracy: 0.2910\n",
            "Epoch 352/400\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 1.6595 - categorical_accuracy: 0.2910\n",
            "Epoch 353/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6592 - categorical_accuracy: 0.2910\n",
            "Epoch 354/400\n",
            "22/22 [==============================] - 2s 90ms/step - loss: 1.6590 - categorical_accuracy: 0.2910\n",
            "Epoch 355/400\n",
            "22/22 [==============================] - 3s 122ms/step - loss: 1.6587 - categorical_accuracy: 0.2910\n",
            "Epoch 356/400\n",
            "22/22 [==============================] - 2s 94ms/step - loss: 1.6584 - categorical_accuracy: 0.2910\n",
            "Epoch 357/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6581 - categorical_accuracy: 0.2910\n",
            "Epoch 358/400\n",
            "22/22 [==============================] - 2s 72ms/step - loss: 1.6578 - categorical_accuracy: 0.2910\n",
            "Epoch 359/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6575 - categorical_accuracy: 0.2910\n",
            "Epoch 360/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.6573 - categorical_accuracy: 0.2910\n",
            "Epoch 361/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6570 - categorical_accuracy: 0.2910\n",
            "Epoch 362/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6568 - categorical_accuracy: 0.2910\n",
            "Epoch 363/400\n",
            "22/22 [==============================] - 3s 119ms/step - loss: 1.6564 - categorical_accuracy: 0.2910\n",
            "Epoch 364/400\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 1.6576 - categorical_accuracy: 0.2910\n",
            "Epoch 365/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.6589 - categorical_accuracy: 0.2896\n",
            "Epoch 366/400\n",
            "22/22 [==============================] - 2s 70ms/step - loss: 1.6538 - categorical_accuracy: 0.2910\n",
            "Epoch 367/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6549 - categorical_accuracy: 0.2896\n",
            "Epoch 368/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.6544 - categorical_accuracy: 0.2882\n",
            "Epoch 369/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6520 - categorical_accuracy: 0.2939\n",
            "Epoch 370/400\n",
            "22/22 [==============================] - 1s 66ms/step - loss: 1.6512 - categorical_accuracy: 0.2953\n",
            "Epoch 371/400\n",
            "22/22 [==============================] - 2s 82ms/step - loss: 1.6503 - categorical_accuracy: 0.2953\n",
            "Epoch 372/400\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 1.6493 - categorical_accuracy: 0.2939\n",
            "Epoch 373/400\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 1.6506 - categorical_accuracy: 0.2924\n",
            "Epoch 374/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.6501 - categorical_accuracy: 0.2953\n",
            "Epoch 375/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6483 - categorical_accuracy: 0.2939\n",
            "Epoch 376/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 1.6497 - categorical_accuracy: 0.2953\n",
            "Epoch 377/400\n",
            "22/22 [==============================] - 2s 71ms/step - loss: 1.6489 - categorical_accuracy: 0.2953\n",
            "Epoch 378/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 1.6455 - categorical_accuracy: 0.2953\n",
            "Epoch 379/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.6445 - categorical_accuracy: 0.2953\n",
            "Epoch 380/400\n",
            "22/22 [==============================] - 2s 81ms/step - loss: 1.6530 - categorical_accuracy: 0.2924\n",
            "Epoch 381/400\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 1.6486 - categorical_accuracy: 0.2939\n",
            "Epoch 382/400\n",
            "22/22 [==============================] - 2s 101ms/step - loss: 1.6449 - categorical_accuracy: 0.2967\n",
            "Epoch 383/400\n",
            "22/22 [==============================] - 1s 65ms/step - loss: 2.1851 - categorical_accuracy: 0.2382\n",
            "Epoch 384/400\n",
            "22/22 [==============================] - 1s 68ms/step - loss: 1.6122 - categorical_accuracy: 0.2653\n",
            "Epoch 385/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.5190 - categorical_accuracy: 0.3167\n",
            "Epoch 386/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.4775 - categorical_accuracy: 0.3923\n",
            "Epoch 387/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.4621 - categorical_accuracy: 0.4023\n",
            "Epoch 388/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.3955 - categorical_accuracy: 0.3894\n",
            "Epoch 389/400\n",
            "22/22 [==============================] - 2s 76ms/step - loss: 1.3440 - categorical_accuracy: 0.4208\n",
            "Epoch 390/400\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 1.2821 - categorical_accuracy: 0.4750\n",
            "Epoch 391/400\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 1.2131 - categorical_accuracy: 0.5078\n",
            "Epoch 392/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.1182 - categorical_accuracy: 0.5264\n",
            "Epoch 393/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.0981 - categorical_accuracy: 0.5307\n",
            "Epoch 394/400\n",
            "22/22 [==============================] - 1s 64ms/step - loss: 1.0507 - categorical_accuracy: 0.5193\n",
            "Epoch 395/400\n",
            "22/22 [==============================] - 1s 67ms/step - loss: 1.0253 - categorical_accuracy: 0.5150\n",
            "Epoch 396/400\n",
            "22/22 [==============================] - 2s 68ms/step - loss: 0.9693 - categorical_accuracy: 0.5606\n",
            "Epoch 397/400\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.9073 - categorical_accuracy: 0.5863\n",
            "Epoch 398/400\n",
            "22/22 [==============================] - 2s 86ms/step - loss: 9.8162 - categorical_accuracy: 0.3809\n",
            "Epoch 399/400\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 1.6500 - categorical_accuracy: 0.2910\n",
            "Epoch 400/400\n",
            "22/22 [==============================] - 2s 95ms/step - loss: 1.6521 - categorical_accuracy: 0.2910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f472cba00>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoJFm383sLIG",
        "outputId": "99997230-e769-4933-e663-0cea481697fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking_1 (Masking)         (None, 15, 63)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 15, 64)            32768     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 64)            0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 15, 128)           98816     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 15, 128)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 187,430\n",
            "Trainable params: 187,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMa-keodsamL",
        "outputId": "4b508e14-f13f-4ecf-8d87-74997820e4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions[np.argmax(res[2])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t0P-65sisczA",
        "outputId": "e93a3b69-582b-4932-944b-10d6b42bf2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rotateC'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions[np.argmax(y_test[2])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-8NFg-JCsp1h",
        "outputId": "71dee6a8-b4cd-49a2-cb49-dcfc0faf84da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rotateC'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('97percentallstills.h5')"
      ],
      "metadata": {
        "id": "57lyvZsdsw5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('90percent.h5')"
      ],
      "metadata": {
        "id": "Ku9IY6NNyKMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KJHNlk-wOPO",
        "outputId": "00d251b9-b65e-4ddd-e3fd-f127648d2c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('/content/drive/MyDrive/TestTraining/action.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtVKizlswh9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "src_folder = '/content/data/actionHighAcc.h5'\n",
        "dst_folder = '/content/drive/MyDrive/GestureNotebook'\n",
        "shutil.copytree(src_folder, dst_folder)\n"
      ],
      "metadata": {
        "id": "cYRiH1GmxA0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "src_folder = '/content/drive/MyDrive/GestureNotebook'\n",
        "dst_folder = '/content/data'\n",
        "shutil.copytree(src_folder, dst_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "74d3BipftaO9",
        "outputId": "28b7dfc0-db7c-47fd-a90c-28bf1e87ea76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "dne0z1-HyUnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlla4LTOyVo3",
        "outputId": "d8e1151a-5301-4a29-faf3-5b4a589ae5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 3s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()"
      ],
      "metadata": {
        "id": "mSgSEhDByV9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel_confusion_matrix(ytrue, yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDNk6j_aya6a",
        "outputId": "e9ab51a4-af8c-4fec-863e-4e74bd8907d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[141,   1],\n",
              "        [  1,  17]],\n",
              "\n",
              "       [[142,   1],\n",
              "        [  1,  16]],\n",
              "\n",
              "       [[151,   0],\n",
              "        [  0,   9]],\n",
              "\n",
              "       [[150,   0],\n",
              "        [  1,   9]],\n",
              "\n",
              "       [[148,   0],\n",
              "        [  0,  12]],\n",
              "\n",
              "       [[152,   1],\n",
              "        [  0,   7]],\n",
              "\n",
              "       [[140,   0],\n",
              "        [  1,  19]],\n",
              "\n",
              "       [[147,   1],\n",
              "        [  0,  12]],\n",
              "\n",
              "       [[147,   0],\n",
              "        [  0,  13]],\n",
              "\n",
              "       [[144,   0],\n",
              "        [  0,  16]],\n",
              "\n",
              "       [[155,   0],\n",
              "        [  0,   5]],\n",
              "\n",
              "       [[149,   0],\n",
              "        [  0,  11]],\n",
              "\n",
              "       [[154,   0],\n",
              "        [  1,   5]],\n",
              "\n",
              "       [[155,   1],\n",
              "        [  0,   4]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(ytrue, yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZWX4qXKyeTf",
        "outputId": "3feb5495-5353-41aa-f5e6-3218eba6384f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96875"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
        "def prob_viz(res, actions, input_frame, colors):\n",
        "    output_frame = input_frame.copy()\n",
        "    for num, prob in enumerate(res):\n",
        "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
        "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "    return output_frame\n",
        "\n"
      ],
      "metadata": {
        "id": "41uU048l1Mcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.imshow(prob_viz(res, actions, image, colors))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "BNMZrI785UPP",
        "outputId": "356397bc-01b9-47b3-ae10-59b02e2e1120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-a38efa5a5864>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "a = np.loadtxt('teststill')\n",
        "# res = model.predict(np.expand_dims(a, axis=0))[0]\n",
        "res = model.predict(np.expand_dims(a, axis=0), batch_size=32)[0]\n",
        "print(time.time() - start)\n",
        "actions[np.argmax(res)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FHvemAlF_E0W",
        "outputId": "ac16c5bb-9a74-48c3-bc63-c82083e82037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "0.0465238094329834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zoomin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    }
  ]
}